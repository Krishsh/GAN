{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleverhans FGSM attack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishsh/GAN/blob/main/tutorials/future/tf2/notebook_tutorials/mnist_fgsm_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHwgLwN4nXPi"
      },
      "source": [
        "# Fast Gradient Sign Method (FGSM) using Cleverhans\n",
        "\n",
        "#### Easily implement an FGSM attack on a model using Cleverhans and Tensorflow 2.0\n",
        ">\n",
        "Checkout Cleverhans on Github [here](https://www.github.com/tensorflow/cleverhans).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs9wD38he0cM"
      },
      "source": [
        "## Import dependent libraries\n",
        "Tensorflow 2.0 required \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBsLelavnv0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa56e99-fd6f-428d-e6d0-584510df750f"
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 88.7MB 64kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 31.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 32.2MB/s \n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-xiwexx4z/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-xiwexx4z/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 24.1MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/cc/227251b1471f129bc35e966bb0fceb005969023926d744139642d847b7ae/pycodestyle-2.7.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (3.2.2)\n",
            "Collecting mnist\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.12.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.0.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.9)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (1.3.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.1.6)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-4.0.0-cp37-none-any.whl size=92450 sha256=a6a9f6766cb87ec972db46d22c3ac1e42de643321c397f65e538ec7b2b4939d9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-euk6gyln/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-4.0.0 mnist-0.2.2 nose-1.3.7 pycodestyle-2.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tensorflow Version: 2.0.0-beta1\n",
            "Cleverhans Version: 4.0.0-dda3ed9309fe3cd6d5b746c5c9c440d8\n",
            "GPU Available:  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4kgPQqp-hwR"
      },
      "source": [
        "## Training a simple model on the MNIST dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z99mq1bKkjz"
      },
      "source": [
        "> If you would like to experiment with other datasets feel free to replace this code by whatever you need to do so. Just remember that to make the rest of the notebook work without any other major changes keep the variables train_images, train_labels, test_images, test_labels and assign them to the corresponding new data. I recommend any of the datasets offered by keras as they use the same mechanics to import them.\n",
        "\n",
        ">Keep in mind that the MNIST dataset was used in this guide because of the little amount of time it takes to both train a good model and craft the attacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQVP1re__pbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a875c42b-8b2b-4338-becf-e87a8790024a"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Activation(tf.nn.softmax) # We seperate the activation layer to be able to access the logits of the previous layer later\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss= 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, validation_split=0.2)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 81us/sample - loss: 0.4450 - accuracy: 0.8707 - val_loss: 0.2226 - val_accuracy: 0.9368\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 76us/sample - loss: 0.2056 - accuracy: 0.9416 - val_loss: 0.1778 - val_accuracy: 0.9480\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 72us/sample - loss: 0.1591 - accuracy: 0.9531 - val_loss: 0.1603 - val_accuracy: 0.9533\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 72us/sample - loss: 0.1328 - accuracy: 0.9607 - val_loss: 0.1445 - val_accuracy: 0.9586\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 73us/sample - loss: 0.1150 - accuracy: 0.9651 - val_loss: 0.1379 - val_accuracy: 0.9607\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 73us/sample - loss: 0.1024 - accuracy: 0.9696 - val_loss: 0.1397 - val_accuracy: 0.9606\n",
            "Epoch 7/10\n",
            "46784/48000 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9724"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpC4KgTS_Fj8"
      },
      "source": [
        "## Implementing the FGSM attack using fast_gradient_method()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U68CRVKW5ULk"
      },
      "source": [
        "Cleverhans implements the fgsm attack with the following method:\n",
        "\n",
        "\n",
        "```\n",
        "fast_gradient_method(model_fn, x, eps, norm, clip_min=None, clip_max=None, y=None, targeted=False, sanity_checks=False)\n",
        "\n",
        "```\n",
        "\n",
        "> * **model_fn**: a callable that takes an input tensor and returns the model logits\n",
        "* **x**: input_tensor\n",
        "* **eps**: epsilon (dictates the \"strength\" of the distortion created)\n",
        "* **norm**: Order of the norm (mimics NumPy). Possible values: np.inf, 1 or 2.\n",
        "* **clip_min**: (optional, default=None) float. Minimum float value for adversarial example components.\n",
        "* **clip_max**: (optional, default=None) float. Maximum float value for adversarial example components\n",
        "* **y**: (optional, default=None) Tensor with true labels. If targeted is true, then provide the target label. Otherwise, only provide this parameter if you'd like to use true labels when crafting adversarial samples. Otherwise, model predictions are used as labels to avoid the \"label leaking\" effect (explained in this [paper](https://arxiv.org/abs/1611.01236)).\n",
        "* **targeted**: (optional, default=False) bool. Is the attack targeted or untargeted? Untargeted, the default, will try to make the label incorrect. Targeted will instead try to move in the direction of being more like y.\n",
        "* **param sanity_checks**: (optional, default=False) bool, if True, include  asserts (Turn them off to use less runtime / memory or for unit tests that intentionally pass strange input)\n",
        ">\n",
        "\n",
        "Find it in the library [here](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/future/tf2/attacks/fast_gradient_method.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgZhvgzbAuU8"
      },
      "source": [
        "# Import the attack\n",
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(model.input,model.layers[-1].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q53TkEuD-gR9"
      },
      "source": [
        "### Choose a random image to attack from the test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA7_JKrm1wsm"
      },
      "source": [
        "random_index = np.random.randint(test_images.shape[0])\n",
        "\n",
        "original_image = test_images[random_index]\n",
        "original_image = tf.convert_to_tensor(original_image.reshape((1,28,28))) #The .reshape just gives it the proper form to input into the model, a batch of 1 a.k.a a tensor\n",
        "\n",
        "original_label = test_labels[random_index]\n",
        "original_label = np.reshape(original_label, (1,)).astype('int64') # Give label proper shape and type for cleverhans\n",
        "\n",
        "#Show the image\n",
        "plt.figure()\n",
        "plt.grid(False)\n",
        "\n",
        "plt.imshow(np.reshape(original_image, (28,28)))\n",
        "plt.title(\"Label: {}\".format(original_label[0]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz8QBZJ2-DO5"
      },
      "source": [
        "### Non-targeted FGSM attack\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LSemuYWrZWz"
      },
      "source": [
        "epsilon = 0.1\n",
        "\n",
        "adv_example_untargeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, targeted=False)\n",
        "\n",
        "adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "\n",
        "#Show the image\n",
        "plt.figure()\n",
        "plt.grid(False)\n",
        "\n",
        "plt.imshow(np.reshape(adv_example_untargeted_label, (28,28)))\n",
        "plt.title(\"Model Prediction: {}\".format(np.argmax(adv_example_untargeted_label_pred)))\n",
        "plt.xlabel(\"Original Label: {}\".format(original_label[0]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l-eIvZZvSC6"
      },
      "source": [
        "### Targeted FGSM Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4teWeVYvUGQ"
      },
      "source": [
        "epsilon = 0.1\n",
        "# The target value may have to be changed to work, some images are more easily missclassified as different labels\n",
        "target = 2\n",
        "\n",
        "target_label = np.reshape(target, (1,)).astype('int64') # Give target label proper size and dtype to feed through\n",
        "\n",
        "adv_example_targeted_label = fast_gradient_method(logits_model, original_image, epsilon, np.inf, y=target_label, targeted=True)\n",
        "\n",
        "adv_example_targeted_label_pred = model.predict(adv_example_targeted_label)\n",
        "\n",
        "#Show the image\n",
        "plt.figure()\n",
        "plt.grid(False)\n",
        "\n",
        "plt.imshow(np.reshape(adv_example_targeted_label, (28,28)))\n",
        "plt.title(\"Model Prediction: {}\".format(np.argmax(adv_example_targeted_label_pred)))\n",
        "plt.xlabel(\"Original Label: {}\".format(original_label[0]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlQ833TumOUC"
      },
      "source": [
        "### Other Docs\n",
        ">\n",
        "Find more tutorials for Cleverhans [here](https://github.com/tensorflow/cleverhans/tree/master/tutorials/future/tf2)."
      ]
    }
  ]
}